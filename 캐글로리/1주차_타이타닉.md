# ìºê¸€ë¡œë¦¬
## ğŸš£ Titanic í•„ì‚¬ë…¸íŠ¸
### 1. ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°

```python
import pandas as pd
import numpy as np
import random as rnd

import seaborn as sns
import matplotlib.pyplot as plt
%matplotlib inline

from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier
from sklearn.svm import SVC, LinearSVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.tree import DecisionTreeClassifier
```

> kaggle í™˜ê²½ì—ì„œëŠ” `%matplotlib inline`ì´ ìë™ì´ì§€ë§Œ íŒŒì´ì¬ì—ì„œëŠ” í•„ìš” ì—†ìŒ.

---

### 2. ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°

```python
train_df = pd.read_csv('/content/drive/MyDrive/á„ƒá…¡á„á…³á„‡á…µ/0á„á…¡á„‰á…µ.á„á…¡á„‹á…µá„á…¡á„‚á…µá†¨/titanic/asset/train.csv')
test_df = pd.read_csv('/content/drive/MyDrive/á„ƒá…¡á„á…³á„‡á…µ/0á„á…¡á„‰á…µ.á„á…¡á„‹á…µá„á…¡á„‚á…µá†¨/titanic/asset/test.csv')
combine = [train_df, test_df]
```

---

### 3. ë°ì´í„° êµ¬ì¡° í™•ì¸

```python
print(train_df.columns.values)

train_df.info()
print('_'*40)
test_df.info()

train_df.describe()
train_df.describe(include=['O'])
```
- (include=['O']) : ë¬¸ìì—´ íƒ€ì…ì˜ ì—´ë“¤ë§Œ ì¶”ì¶œë¨.
---

### 4. í”¼ì³ë³„ ìƒì¡´ë¥  í™•ì¸

```python
train_df[['Pclass', 'Survived']].groupby('Pclass').mean().sort_values('Survived', ascending=False)

train_df[['Sex', 'Survived']].groupby('Sex').mean().sort_values('Survived', ascending=False)

train_df[['SibSp', 'Survived']].groupby('SibSp').mean()
train_df[['Parch', 'Survived']].groupby('Parch').mean()
```

---

### 5. ì‹œê°í™”(EDA)

```python
sns.FacetGrid(train_df, col='Survived').map(plt.hist, 'Age', bins=20)
sns.FacetGrid(train_df, row='Pclass', col='Survived').map(plt.hist, 'Age', bins=20)
sns.FacetGrid(train_df, row='Embarked', col='Survived').map(sns.barplot, 'Sex', 'Fare', ci=None)
```

---

### 6. í”¼ì³ ì—”ì§€ë‹ˆì–´ë§

#### ì´ë¦„ì—ì„œ Title ì¶”ì¶œ
```python
for dataset in combine:
    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)
```

#### Title ì •ë¦¬ ë° ì¸ì½”ë”©
```python
for dataset in combine:
    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',
        'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')
    dataset['Title'] = dataset['Title'].replace(['Mlle', 'Ms'], 'Miss')
    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')

title_mapping = {"Mr":1, "Miss":2, "Mrs":3, "Master":4, "Rare":5}
for dataset in combine:
    dataset['Title'] = dataset['Title'].map(title_mapping).fillna(0)
```
#### ìƒˆë¡œìš´ í”¼ì²˜ ìƒì„±
```python
for dataset in combine:
    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1
    dataset['IsAlone'] = 0
    dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1
    dataset['Age*Class'] = dataset['Age'] * dataset['Pclass']
```

#### ë¶ˆí•„ìš”í•œ í”¼ì²˜ ì œê±°
```python
train_df = train_df.drop(['SibSp', 'Parch', 'FamilySize'], axis=1)
test_df = test_df.drop(['SibSp', 'Parch', 'FamilySize'], axis=1)
```

#### ë¶„ì„ì— í•„ìš”í•œ ì»¬ëŸ¼ë§Œ ë‚¨ê¸°ê¸°
```python
train_df = train_df.drop(['Name', 'Ticket', 'Cabin', 'PassengerId'], axis=1)
test_df = test_df.drop(['Name', 'Ticket', 'Cabin'], axis=1)
```

### 7. ë°ì´í„° ì¸ì½”ë”© & ê²°ì¸¡ì¹˜ ë³´ê°„

#### Sex â†’ ìˆ«ì ë³€í™˜(ë§¤í•‘)
```python
for dataset in combine:
    dataset['Sex'] = dataset['Sex'].map({'female': 1, 'male': 0}).astype(int)
```
> ì›í•« ì¸ì½”ë”© í•˜ë©´ ë  ê²ƒ ê°™ìŒ.

#### Age â†’ ê·¸ë£¹í™” & ê²°ì¸¡ì¹˜ ë³´ê°„
```python
guess_ages = np.zeros((2,3))
for dataset in combine:
    for i in range(2):
        for j in range(3):
            guess_df = dataset[(dataset['Sex']==i) & (dataset['Pclass']==j+1)]['Age'].dropna()
            age_guess = guess_df.median()
            guess_ages[i,j] = age_guess

    for i in range(2):
        for j in range(3):
            dataset.loc[(dataset.Age.isnull()) & (dataset.Sex==i) & (dataset.Pclass==j+1), 'Age'] = guess_ages[i,j]

    dataset['Age'] = dataset['Age'].astype(int)
```
> ë‚¨/ë…€ * Pclass 6ê°€ì§€ ì¡°í•©ì˜ ì¤‘ì•™ê°’ì„ ì €ì¥í•  ë°°ì—´ ë§Œë“¦. Age ì¤‘ì•™ê°’ ê³„ì‚°í•´ì„œ ì €ì¥. ì„±ë³„ + ê°ì‹¤ ë“±ê¸‰ì´ ë¹„ìŠ·í•œ ì‚¬ëŒë“¤ì˜ ë‚˜ì´ ì¤‘ì•™ê°’ìœ¼ë¡œ ê²°ì¸¡ì¹˜ë¥¼ ì±„ìš´ ê²ƒ.

#### Embarked ê²°ì¸¡ê°’ ì²˜ë¦¬ + ìˆ«ì ì¸ì½”ë”©
```python
freq_port = train_df.Em
for dataset in combine:
    dataset['Embarked'] = dataset['Embarked'].fillna(freq_port)
    dataset['Embarked'] = dataset['Embarked'].map({'S': 0, 'C': 1, 'Q': 2}).astype(int)
```
> ì§€ì—­ì  íŠ¹ì„± ë°˜ì˜

##### Fare ê²°ì¸¡ê°’ ì²˜ë¦¬ + êµ¬ê°„í™”
```python
test_df['Fare'].fillna(test_df['Fare'].dropna().median(), inplace=True)
train_df['FareBand'] = pd.qcut(train_df['Fare'], 4)
for dataset in combine:
    dataset.loc[dataset['Fare'] <= 7.91, 'Fare'] = 0
    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1
    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare'] = 2
    dataset.loc[dataset['Fare'] > 31, 'Fare'] = 3
    dataset['Fare'] = dataset['Fare'].astype(int)
train_df = train_df.drop(['FareBand'], axis=1)
```
### ëª¨ë¸ë§
```python
# í•™ìŠµìš© ì…ë ¥ ë°ì´í„°ì™€ íƒ€ê²Ÿ(ì •ë‹µ) ë°ì´í„° ë¶„ë¦¬
X_train = train_df.drop("Survived", axis=1)
Y_train = train_df["Survived"]

# í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° ë³µì‚¬
X_test  = test_df.copy()

# ëª¨ë¸ ì´ë¦„ê³¼ ì •í™•ë„(í›ˆë ¨ ë°ì´í„° ê¸°ì¤€)ë¥¼ ì €ì¥í•  ë¦¬ìŠ¤íŠ¸
models = []

# Logistic Regression (ë¡œì§€ìŠ¤í‹± íšŒê·€)
logreg = LogisticRegression()
logreg.fit(X_train, Y_train)
models.append(('Logistic Regression', logreg.score(X_train, Y_train)))

# Support Vector Classifier (ì„œí¬íŠ¸ ë²¡í„° ë¨¸ì‹ )
svc = SVC()
svc.fit(X_train, Y_train)
models.append(('SVC', svc.score(X_train, Y_train)))

# K-Nearest Neighbors (KNN, ê°€ì¥ ê°€ê¹Œìš´ ì´ì›ƒ)
knn = KNeighborsClassifier(n_neighbors=3)
knn.fit(X_train, Y_train)
models.append(('KNN', knn.score(X_train, Y_train)))

# Gaussian Naive Bayes (ê°€ìš°ì‹œì•ˆ ë‚˜ì´ë¸Œ ë² ì´ì¦ˆ)
gaussian = GaussianNB()
gaussian.fit(X_train, Y_train)
models.append(('Naive Bayes', gaussian.score(X_train, Y_train)))

# Perceptron (ë‹¨ìˆœ ì‹ ê²½ë§ êµ¬ì¡°)
perceptron = Perceptron()
perceptron.fit(X_train, Y_train)
models.append(('Perceptron', perceptron.score(X_train, Y_train)))

# Linear Support Vector Classifier (ì„ í˜• SVM)
linear_svc = LinearSVC()
linear_svc.fit(X_train, Y_train)
models.append(('Linear SVC', linear_svc.score(X_train, Y_train)))

# Stochastic Gradient Descent (í™•ë¥ ì  ê²½ì‚¬í•˜ê°•ë²•)
sgd = SGDClassifier()
sgd.fit(X_train, Y_train)
models.append(('SGD', sgd.score(X_train, Y_train)))

# Decision Tree (ì˜ì‚¬ ê²°ì • íŠ¸ë¦¬)
decision_tree = DecisionTreeClassifier()
decision_tree.fit(X_train, Y_train)
models.append(('Decision Tree', decision_tree.score(X_train, Y_train)))

# Random Forest (ëœë¤ í¬ë ˆìŠ¤íŠ¸, ì•™ìƒë¸” í•™ìŠµ)
random_forest = RandomForestClassifier(n_estimators=100)
random_forest.fit(X_train, Y_train)
models.append(('Random Forest', random_forest.score(X_train, Y_train)))

# í›ˆë ¨ ì •í™•ë„ë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì„±ëŠ¥ ìˆœìœ„ ì¶œë ¥
for name, score in sorted(models, key=lambda x: x[1], reverse=True):
    print(f"{name}: {score:.4f}")barked.dropna().mode()[0]
```
### ğŸ“Š ëª¨ë¸ë³„ ì„±ëŠ¥ ë° íŠ¹ì§• ë¹„êµí‘œ

| ëª¨ë¸                | í›ˆë ¨ ì •í™•ë„ | ì¥ì                                      | ë‹¨ì                                  | íŠ¹ì§• ìš”ì•½                     |
|---------------------|--------------|------------------------------------------|--------------------------------------|-------------------------------|
| Random Forest       | â˜…â˜…â˜…â˜…â˜…       | ê³¼ì í•© ë°©ì§€, ë³€ìˆ˜ ì¤‘ìš”ë„ ì¶”ì¶œ ê°€ëŠ¥        | ëŠë¦´ ìˆ˜ ìˆìŒ                         | ì•™ìƒë¸” ê¸°ë°˜, ì•ˆì •ì  ì„±ëŠ¥       |
| Decision Tree       | â˜…â˜…â˜…â˜…â˜…       | ì§ê´€ì  í•´ì„, ë¹ ë¥¸ ì†ë„                    | ê³¼ì í•©ì— ë¯¼ê°                        | ë‹¨ì¼ ê²°ì • íŠ¸ë¦¬, ì§ê´€ì          |
| KNN                 | â˜…â˜…â˜…â˜…â˜†       | êµ¬í˜„ ë‹¨ìˆœ, íŠœë‹ ì‰¬ì›€                      | ëŠë¦¼, ê³ ì°¨ì› ë°ì´í„°ì— ì·¨ì•½           | ì£¼ë³€ ë°ì´í„° ê¸°ë°˜ ë¶„ë¥˜          |
| SVC (RBF)           | â˜…â˜…â˜…â˜…â˜†       | ë¹„ì„ í˜• ë¶„ë¥˜ì— ê°•í•¨                        | ëŠë¦¼, íŒŒë¼ë¯¸í„° íŠœë‹ í•„ìš”             | ë§ˆì§„ ê¸°ë°˜ ë¶„ë¥˜ê¸°              |
| Logistic Regression | â˜…â˜…â˜…â˜…â˜†       | ë¹ ë¦„, í™•ë¥  ì˜ˆì¸¡ ê°€ëŠ¥                      | ë¹„ì„ í˜• ë¬¸ì œì— ì•½í•¨                   | ì„ í˜• íšŒê·€ ê¸°ë°˜ ë¶„ë¥˜            |
| Linear SVC          | â˜…â˜…â˜…â˜…â˜†       | ë¹ ë¦„, ê³ ì°¨ì› ë°ì´í„°ì— ì˜ ì‘ë™             | ë¹„ì„ í˜• ë¬¸ì œì— ë¶€ì í•©                 | ì„ í˜• ë§ˆì§„ ë¶„ë¥˜ê¸°              |
| Perceptron          | â˜…â˜…â˜…â˜†â˜†       | ë‹¨ìˆœ êµ¬ì¡°, ë¹ ë¥¸ í•™ìŠµ                      | ì•ˆì •ì„± ë‚®ìŒ, ë¹„ì„ í˜•ì— ì•½í•¨           | ê³ ì „ì  ì‹ ê²½ë§                  |
| SGD Classifier      | â˜…â˜…â˜…â˜†â˜†       | ë§¤ìš° ë¹ ë¦„, ëŒ€ìš©ëŸ‰ ë°ì´í„°ì— ì í•©           | ë¶ˆì•ˆì •, íŠœë‹ ì–´ë ¤ì›€                  | ê²½ì‚¬í•˜ê°• ê¸°ë°˜ ì„ í˜• ë¶„ë¥˜ê¸°      |
| Naive Bayes         | â˜…â˜…â˜†â˜†â˜†       | ë¹ ë¦„, ì ì€ ë°ì´í„°ì—ë„ ì˜ ì‘ë™             | ë…ë¦½ì„± ê°€ì •ì´ í˜„ì‹¤ê³¼ ë‹¤ë¦„            | í™•ë¥  ê¸°ë°˜, í…ìŠ¤íŠ¸ì— ì í•©       |

### ê²°ê³¼ ì˜ˆì¸¡ ë° ì œì¶œ íŒŒì¼ ìƒì„±
```python
Y_pred = random_forest.predict(X_test)
submission = pd.DataFrame({
    "PassengerId": test_df["PassengerId"],
    "Survived": Y_pred
})
submission.to_csv('submission.csv', index=False)
```
### ëª¨ë¸ ì„±ëŠ¥
![alt text](../image/1.png)

## ì¸ì‚¬ì´íŠ¸
> Title í”¼ì²˜, ê²°ì¸¡ê°’ ì²˜ë¦¬, ëª¨ë¸ë§(ëª¨ë¸ì˜ ì¢…ë¥˜), ê³¼ì í•© ì—¬ë¶€?

## ìŠ¤í„°ë”” í›„
- SVM : ë¡œì§€ìŠ¤í‹± íšŒê·€ëª¨í˜• ë‹¨ì  ë³´ì™„. ì§€ë„í•™ìŠµ ì•Œê³ ë¦¬ì¦˜.
  - **ë¶„ë¥˜ ë¬¸ì œ**ì—ì„œì˜ SVM : ì—¬ë°±(ë§ˆì§„)ì´ë€ ì£¼ì–´ì§„ ë°ì´í„°ê°€ ì˜¤ë¥˜ë¥¼ ë°œìƒì‹œí‚¤ì§€ ì•Šê³  ì›€ì§ì¼ ìˆ˜ ìˆëŠ” ìµœëŒ€ ê³µê°„. ì—¬ë°±ì´ ì‘ë‹¤ëŠ” ê²ƒì€ ìƒˆë¡œìš´ ë°ì´í„°ê°€ ë“¤ì–´ì˜¬ ê²½ìš° ì˜¤ë¥˜ê°€ ë°œìƒí•  ê°€ëŠ¥ì„±ì´ ë†’ë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸.
  - **íšŒê·€ ë¬¸ì œ**ì—ì„œì˜ SVM : ì˜¤ë¥˜ê°€ ë°œìƒí•˜ì§€ ì•ŠëŠ” ë²”ìœ„ê°€ ì—¬ë°±ì„.
  - SVMì˜ ì¢…ë¥˜
    - ì„ í˜• SVM : 2D, 3D í˜•íƒœë¡œ ë°ì´í„° ë‚˜ëˆ”.
    - ë¹„ì„ í˜• SVM : 
- ëª¨ë¸ì—ê²Œ ì„œì—´ì•Œë ¤ì¤„ ë•Œ
: ë§¤í•‘ -> ì¸ì½”ë”©