# 6주차 캐글 필사 리마인드 학습
## 1주차 타이타닉
### 리마인드
> 남/녀 * Pclass 6가지 조합의 중앙값을 저장할 배열 만듦. Age 중앙값 계산해서 저장. 성별 + 객실 등급이 비슷한 사람들의 나이 중앙값으로 결측치를 채운 것.

> (include=['O']) : 문자열 타입의 열들만 추출됨.

### 보완해야할 점
- SVM 개념 더 정리 필요:
  - SVM은 로지스틱 회귀의 단점을 보완한 지도학습 알고리즘.

  - 분류 문제에서는 여백(마진) 개념 중요 — 데이터가 오류 없이 이동할 수 있는 최대 공간.

  - 여백이 작으면 새로운 데이터가 들어왔을 때 오류 발생 가능성 ↑.

  - 회귀 문제에서는 오류가 발생하지 않는 범위가 여백임.

- SVM 종류:
  - 선형 SVM: 2D, 3D 형태로 데이터 나눔.
  - 비선형 SVM: 커널 트릭 사용하여 고차원에서 분리.

- 인코딩/매핑 정리:
  - 모델에게 서열을 알려줄 때 → 매핑 후 인코딩 필요
  - 예) age는 title의 평균값으로 매핑 가능.

- 분석 관련 메서드/옵션 정리:
  - Tukey method: 분산분석(ANOVA) 사후 분석 시 사용.- annot=True: 숫자로 결과 출력.
  - rotation: 레이블 이름을 대각선으로 설정.
  - setp: 객체 속성 일괄 설정.
  - prefix: 접두사(변수명 앞에 붙이기).

- 데이터 전처리:
  - 이상치 처리: 2개 이상 이상치를 가진 행 제거.
  - FamilySize: 범주형으로 변환 후 활용.

- 학습 곡선 개념 숙지:
  - 과적합 여부 확인 및 훈련 데이터 크기에 따른 정확도 변화 시각화.
  - 학습곡선 차이가 크면 → 과대적합 또는 과소적합 의심.

- 앙상블 모델링 개념 숙지:
  - 배깅(Bagging): 데이터를 여러 번 샘플링 → 여러 모델 학습 → 결과 평균/투표.
  - 부스팅(Boosting): 이전 모델이 틀린 데이터에 가중치를 두어 학습.
  - 스태킹(Stacking): 여러 모델 결과를 새로운 모델의 입력으로 사용하여 학습.
  - 보팅(Voting): 여러 분류기의 예측 결과 → 다수결(hard) 또는 확률 평균(soft)으로 최종 결정.

## 2주차 Porto Seguro
### 리마인드
> 출력 결과를 보기 좋게 정리하기 위해 보조함수를 만듦.

> 타겟별로 히스토그램, 교차표, 기술통계 자동 출력. 연속형 변수는 평균, 분산, 왜도, 첨도 포함한 통계 출력.

> EDA 유틸 함수, 결측치 처리 함수 등 많은 함수를 써 자동화함.

### 보완해야할 점
- 시각화 2개:
  - 예측 확률 분포 히스토그램 (train/test)
  - 에폭별 손실 그래프 (5번째 이후부터)
→ 모델이 어떻게 예측했고, 과적합은 없는지 시각적으로 확인할 수 있음.

> ① 예측 확률 분포 히스토그램 (train/test) :
모델이 예측한 확률 값이 어떤 분포로 나오는지를 train/test 데이터 각각에 대해 히스토그램으로 보는 것.

> train 데이터 분포 vs test 데이터 분포 비교 가능 : train에서는 확실하게(0 또는 1 쪽으로) 치우친 예측을 했는데 test는 애매한 예측(중간값) 이 많으면 → 과적합 의심. 반대로 둘 다 비슷하게 예측하면 → 일반화 잘 된 것\
또 한 가지 : 예측이 확신 있는 쪽으로 (0 근처, 1 근처) 모이면 좋은 모델. 중간 (0.4~0.6) 확률이 많으면 → 모델이 헷갈리고 있다는 뜻.

> ② 에폭별 손실 그래프 (5번째 이후부터)
→ 흔히 training loss vs validation loss 그래프

> train loss는 줄어드는데 validation loss는 증가하면 → 과적합. 둘 다 비슷하게 줄어들고 유지되면 → 과적합 없음, 학습 잘 됨.\
왜 5번째 이후부터?\
처음 1~4 epoch은 warm-up 단계에서 loss 변동이 크고 불안정 → noise 많음. 5 epoch 이후부터 안정적으로 학습되는 구간이므로 그때부터 그래프를 해석하는 게 좋음.

## 3주차 New York City Taxi Trip Duration
### 리마인드
1️⃣ 공항 근처 영역 정의\
2️⃣ train 데이터에서 해당 영역 내 행만 추출\
3️⃣ trip_duration이 15분인 짧은 trip만 추출\
4️⃣ 각 trip을 Line으로 표현 (시작 → 끝)\
5️⃣ GeoJSON으로 변환 (folium용)\
6️⃣ TimestampedGeoJson으로 시간 흐름 애니메이션 지도 완성
### 보완해야할 점
> folium 기본 기능 -> 정적 지도.
folium.plugins.TimestampedGeoJson 은 시간 정보 (times) 를 넣으면 지도에서 시간 슬라이더가 생김 → 시간을 움직이면서 애니메이션으로 보여줌.

> PolyLine with time plugin : 움직이는 선(dot이 움직임) 시간 슬라이더는 없음.

> 더 고급 시각화는 : Kepler.gl / deck.gl

## 4주차 House Prices - Advanced Regression Techniques
### 리마인드
> 범주형 변수와 수치형 변수를 나눠줌. 모델링 전처리할 때 좋음.

> 모든 수치병 변수들이 정규성을 만족하는지 테스트. 정규성을 만족하지 않으면 로그변환해주거나, 비모수 검정하거나..

> 고차원 데이터를 2차원으로 비선형 축소할 때, KMeans가 군집화 수행. (PCA가 차원 축소)

> 여러 모델의 예측값을 블렌딩, 앙상블.

### 보완해야할 점
- Box-Cox는 양수 변수만 사용 가능 (음수/0 이 포함된 변수는 사용할 수 없음 → 사전 처리 필요)

- lambda 최적화를 위해 약간 계산 비용이 듦 → 대용량 데이터에서는 속도 고려

- 트리 계열 모델 (예: Random Forest, XGBoost)은 정규성 보정 영향이 크지 않음 → 선형모델 계열에서 더 효과적

- 변환 후 역변환 시 해석이 어려울 수 있음 → 모델 제출/해석용 변수는 따로 저장 필요
  - 📍Box-Cox는 lambda(λ) 값이 필요
λ 값이 있어야 나중에 역변환 가능. 근데 일반적으로 boxcox() 할 때 → 변환값만 저장하고 lambda는 버리는 경우가 많음
→ 그러면 나중에 역변환 못함.

## 5주차  PetFinder.my Adoption Prediction
### 리마인드
> pet 정보를 md5 해싱하여 고유 식별값을 생성.
> 유출된 데이터셋을 dict으로 변환
벤다이어그램으로 중복확인.

### 보완해야할 점
> 사용했던 코드는 치팅에 쓰이는 코드..

- Laplacian 연산자 : 개념
이미지의 경계(Edge) 선명도를 측정하는 데 사용하는 필터. 경계가 뚜렷한지 흐린지를 수치로 확인 가능.
  - 작동 원리
픽셀 밝기 변화의 2차 미분(Laplacian)을 계산하여 경계가 급격하게 변하는 영역(Edge)을 강조.
     - 1차 미분 (gradient) → 밝기가 얼마나 빠르게 변하는지
     - 2차 미분 (Laplacian) → 밝기 변화의 변화량이 얼마나 급격한지
     - blur_score 높음 → 선명한 이미지 (경계가 또렷함)
     - blur_score 낮음 → 흐린 이미지 (경계가 뭉개짐)